# ğŸ  PPIV - Sistema de Reservas para Alojamientos Temporales

Sistema completo de gestiÃ³n y reservas para alojamientos temporales con frontend React, backend Flask, y pipeline CI/CD automatizado. Permite a propietarios gestionar sus propiedades y a huÃ©spedes realizar el check-in.

## ğŸ“‹ Ãndice

- [ğŸ¯ DescripciÃ³n del Sistema](#-descripciÃ³n-del-sistema)
- [ğŸŒ Entornos de EjecuciÃ³n](#-entornos-de-ejecuciÃ³n)
- [ğŸ—ï¸ Arquitectura del Sistema](#ï¸-arquitectura-del-sistema)
- [ğŸš€ Pipeline CI/CD Automatizado](#-pipeline-cicd-automatizado)
- [ğŸ“¦ InstalaciÃ³n y ConfiguraciÃ³n](#-instalaciÃ³n-y-configuraciÃ³n)
- [ğŸ§ª Sistema de Tests](#-sistema-de-tests)
- [ğŸ  Funcionalidades del Sistema](#-funcionalidades-del-sistema)
- [ğŸ“ Estructura del Proyecto](#-estructura-del-proyecto)
- [ğŸ”„ Flujo de Deploy AutomÃ¡tico](#-flujo-de-deploy-automÃ¡tico)
- [ğŸ› ï¸ Comandos Ãštiles](#ï¸-comandos-Ãºtiles)
- [ğŸ“Š Monitoreo con Prometheus + Grafana](#-monitoreo-con-prometheus--grafana)
- [ğŸ”§ ConfiguraciÃ³n Avanzada](#-configuraciÃ³n-avanzada)
- [ğŸš¨ Troubleshooting](#-troubleshooting)
- [ğŸ—ï¸ Infraestructura como CÃ³digo con Terraform](#ï¸-infraestructura-como-cÃ³digo)
- [ğŸ“š DocumentaciÃ³n Adicional](#-documentaciÃ³n-adicional)
- [ğŸ¤ ContribuciÃ³n](#-contribuciÃ³n)
- [ğŸ“ Soporte](#-soporte)

---

## ğŸ¯ DescripciÃ³n del Sistema

**Omeguitas** es una plataforma para administradores de alojamientos temporales que centraliza y facilita las siguientes funcionalidades:

- **ğŸ  GestiÃ³n de Propiedades**: AdministraciÃ³n completa de unidades de alojamiento
- **ğŸ“… Sistema de Reservas**: Calendario interactivo y proceso de reserva simplificado
- **ğŸ‘¥ GestiÃ³n de Usuarios**: CRUD de administradores del sistema
- **ğŸ’° GestiÃ³n de Precios**: Multiplicadores por temporada y configuraciones flexibles
- **ğŸ“Š Reportes**: Informes detallados de ocupaciÃ³n y rentabilidad
- **ğŸ“§ Notificaciones**: Sistema de emails automÃ¡ticos para check-in

---

## ğŸŒ Entornos de EjecuciÃ³n

### ğŸ”§ Desarrollo Local (Docker)

- **Frontend y Backend**: Se levantan como contenedores Docker usando `docker-compose.dev.yml`.
- **Base de datos**: Se levanta automÃ¡ticamente en un contenedor MySQL llamado `ppiv_mysql_dev`.
  - El esquema y los datos iniciales se cargan desde el archivo `init.sql` al iniciar el contenedor.
- **Comando para levantar todo**:
  ```bash
  docker-compose -f docker-compose.dev.yml up -d
  ```
- **Acceso**:
  - Frontend: http://localhost:3000
  - Backend: http://localhost:5000
  - MySQL: localhost:3306 (usuario y contraseÃ±a definidos en `.env` o variables por defecto)

### ğŸš€ ProducciÃ³n (Render + Vercel)

- **Backend**: Deploy automÃ¡tico en Render.com (PaaS) usando GitHub Actions.
- **Frontend**: Deploy automÃ¡tico en Vercel.com (PaaS) usando GitHub Actions.
- **Base de datos**: Servicio gestionado en Filess.io, accesible desde ambos entornos.
- **Deploys**:
  - Se disparan automÃ¡ticamente al hacer push a la rama `main` en GitHub.
  - GitHub Actions ejecuta tests y, si todo pasa, hace deploy usando los webhooks de Render y Vercel (URLs configuradas como secrets en GitHub).
- **Health checks**: Ambos servicios tienen health checks automÃ¡ticos tras el deploy.

### âš™ï¸ ConfiguraciÃ³n AutomÃ¡tica

El sistema detecta automÃ¡ticamente el entorno y configura la base de datos segÃºn corresponda:

```python
# En config.py
if IS_PRODUCTION:
    # Usa Filess.io (producciÃ³n)
    DB_CONFIG = {
        'host': 'pk3b0.h.filess.io',
        'database': 'alojamientosomeguitas_particles',
        # ...
    }
else:
    # Usa MySQL local (desarrollo)
    DB_CONFIG = {
        'host': 'mysql',
        'database': 'ppiv_db',
        # ...
    }
```

---

## ğŸ—ï¸ Arquitectura del Sistema

```mermaid
graph TB
    A[Frontend React/Vite] --> B[Backend Flask API]
    B --> C[MySQL Database]
    B --> D[Email Service]
    B --> E[File Storage]

    F[GitHub Actions] --> G[Tests & Build]
    G --> H[Render Backend]
    G --> I[Vercel Frontend]

    style A fill:#61dafb
    style B fill:#007bff
    style C fill:#ff6b35
    style F fill:#28a745
```

### ğŸ¨ Frontend (React + Vite)

- **Framework**: React 18 con Vite
- **UI**: Componentes modernos y responsivos
- **Estado**: Context API para gestiÃ³n global
- **Routing**: React Router para navegaciÃ³n
- **Deploy**: Vercel (automÃ¡tico)

### ğŸ”§ Backend (Flask + Python)

- **Framework**: Flask con rutas REST
- **AutenticaciÃ³n**: JWT tokens
- **Base de datos**: MySQL con Flask-MySQL
- **Emails**: Flask-Mail con templates
- **Deploy**: Render (automÃ¡tico)

### ğŸ—„ï¸ Base de Datos

- **Desarrollo**: MySQL en Docker
- **ProducciÃ³n**: MySQL en Filess.io
- **Migraciones**: Scripts SQL manuales

---

## ğŸš€ Pipeline CI/CD Automatizado

### ğŸ“‹ Workflow de GitHub Actions

```mermaid
graph LR
    A[Push a main] --> B[Tests Backend]
    A --> C[Tests Frontend]
    A --> D[Linting]
    B --> E[Build Docker]
    C --> E
    D --> E
    E --> F[Deploy Render]
    E --> G[Deploy Vercel]
```

### ğŸ”„ Flujo Detallado del Pipeline

```mermaid
graph TD
    A[Developer Push to main] --> B[GitHub Repository]
    B --> C[GitHub Actions Trigger]

    C --> D[Checkout Code]
    D --> E[Setup Python & Node.js]

    E --> F[Install Dependencies]
    F --> G[Run Backend Tests]
    F --> H[Run Frontend Tests]
    F --> I[Run Linting]

    G --> J{Tests Pass?}
    H --> J
    I --> J

    J -->|Yes| K[Build Docker Images]
    J -->|No| Z[Fail Pipeline]

    K --> L[Push to GitHub Container Registry]
    L --> M[Security Scan]

    M --> N[Deploy to Render Backend]
    M --> O[Deploy to Vercel Frontend]

    N --> P[Health Check Backend]
    O --> Q[Health Check Frontend]

    P --> R{Deploy Success?}
    Q --> R

    R -->|Yes| S[Notify Success]
    R -->|No| T[Notify Failure]

    S --> U[Update Monitoring]
    T --> U

    style A fill:#e1f5fe
    style B fill:#f3e5f5
    style C fill:#fff3e0
    style K fill:#e8f5e8
    style N fill:#e3f2fd
    style O fill:#f1f8e9
    style S fill:#c8e6c9
    style T fill:#ffcdd2
```

### ğŸ—ï¸ Arquitectura de Infraestructura

```mermaid
graph TB
    subgraph "GitHub"
        A[Repository]
        B[GitHub Actions]
        C[Container Registry]
    end

    subgraph "Cloud Services"
        D[Render - Backend]
        E[Vercel - Frontend]
        F[Filess.io - MySQL]
    end

    subgraph "Monitoring"
        G[Prometheus]
        H[Grafana]
        I[Alert Manager]
    end

    A --> B
    B --> C
    B --> D
    B --> E

    D --> F
    E --> D

    D --> G
    E --> G
    G --> H
    H --> I
```

### ğŸ”„ Flujo de Desarrollo

```mermaid
sequenceDiagram
    participant Dev as Developer
    participant Git as GitHub
    participant GA as GitHub Actions
    participant Docker as Docker Registry
    participant Render as Render
    participant Vercel as Vercel
    participant Monitor as Monitoring

    Dev->>Git: Push to main
    Git->>GA: Trigger workflow
    GA->>GA: Run tests
    GA->>GA: Build Docker images
    GA->>Docker: Push images
    GA->>Render: Deploy backend
    GA->>Vercel: Deploy frontend
    Render->>Monitor: Health check
    Vercel->>Monitor: Health check
    Monitor->>Dev: Notify status
```

### âœ… Jobs del Pipeline

1. **ğŸ§ª Test Backend**

   - Tests unitarios con pytest
   - Cobertura de cÃ³digo
   - Base de datos MySQL en contenedor
   - Upload de coverage a Codecov

2. **ğŸ¨ Test Frontend**

   - Build de producciÃ³n
   - Tests de componentes
   - ValidaciÃ³n de dependencias
   - VerificaciÃ³n de build exitoso

3. **ğŸ¤– Test Frontend E2E (Selenium)**

   - Tests E2E con Selenium
   - InstalaciÃ³n automÃ¡tica de Chrome
   - Tests de login y funcionalidades crÃ­ticas
   - EjecuciÃ³n en entorno headless

4. **ğŸ” Linting**

   - Python: Flake8 + Black
   - JavaScript: ESLint
   - ValidaciÃ³n de formato
   - Resumen de resultados

5. **ğŸ³ Build Docker**

   - ConstrucciÃ³n de imÃ¡genes
   - Push a GitHub Container Registry
   - Cache optimizado
   - Nombres de imÃ¡genes en minÃºsculas

6. **ğŸŒ Deploy AutomÃ¡tico**
   - Backend â†’ Render
   - Frontend â†’ Vercel
   - Notificaciones de estado
   - Health checks automÃ¡ticos

### ğŸ“Š MÃ©tricas del Pipeline

| Job               | Tiempo Promedio | Objetivo |
| ----------------- | --------------- | -------- |
| Test Backend      | ~3-5 min        | < 5 min  |
| Test Frontend     | ~2-3 min        | < 3 min  |
| Test Frontend E2E | ~2-4 min        | < 4 min  |
| Linting           | ~1-2 min        | < 2 min  |
| Build Docker      | ~4-6 min        | < 6 min  |
| Deploy Backend    | ~2-4 min        | < 4 min  |
| Deploy Frontend   | ~1-2 min        | < 2 min  |

### ğŸ“ˆ Cobertura de Tests

| Componente | Cobertura Actual | Objetivo |
| ---------- | ---------------- | -------- |
| Backend    | ~85%             | > 80%    |
| Frontend   | Build validation | Build OK |

### ğŸ”§ ConfiguraciÃ³n Detallada del Pipeline

#### **Services MySQL para Tests**

```yaml
services:
  mysql:
    image: mysql:8.0
    env:
      MYSQL_ROOT_PASSWORD: rootpassword
      MYSQL_DATABASE: ppiv_db
      MYSQL_USER: ppiv_user
      MYSQL_PASSWORD: ppiv_password
    options: >-
      --health-cmd "mysqladmin ping"
      --health-interval 10s
      --health-timeout 5s
      --health-retries 5
    ports:
      - 3306:3306
```

#### **Cache de Dependencias**

```yaml
# Python dependencies
- name: Cache pip dependencies
  uses: actions/cache@v3
  with:
    path: ~/.cache/pip
    key: ${{ runner.os }}-pip-${{ hashFiles('ProyectoPPVI/requirements.txt') }}

# Node.js dependencies
- name: Set up Node.js
  uses: actions/setup-node@v4
  with:
    node-version: "20"
    cache: "npm"
    cache-dependency-path: PI-PPIV-Front/package-lock.json
```

#### **Docker Buildx con Cache**

```yaml
- name: Set up Docker Buildx
  uses: docker/setup-buildx-action@v3

- name: Build and push images
  uses: docker/build-push-action@v5
  with:
    context: ./ProyectoPPVI
    push: true
    tags: ${{ steps.image-names.outputs.backend-image }}:main
    cache-from: type=gha
    cache-to: type=gha,mode=max
```

### ğŸ‰ Pipeline en ProducciÃ³n

![Pipeline CI/CD Exitoso](./docs/images/pipeline%20okay.png)

_Pipeline completo funcionando en GitHub Actions con todos los jobs ejecutÃ¡ndose exitosamente._

**Estado Actual**: âœ… **FUNCIONANDO**

- **Ãšltima ejecuciÃ³n**: Exitoso
- **Tasa de Ã©xito**: 100%
- **Tiempo total**: ~5-7 minutos

### ğŸ“Š Estados del Pipeline

```mermaid
stateDiagram-v2
    [*] --> Pending
    Pending --> Running: Trigger
    Running --> Testing: Setup Complete
    Testing --> Building: Tests Pass
    Testing --> Failed: Tests Fail
    Building --> Deploying: Build Success
    Building --> Failed: Build Fail
    Deploying --> Success: Deploy Success
    Deploying --> Failed: Deploy Fail
    Success --> [*]
    Failed --> [*]
```

### ğŸ³ GitHub Container Registry

#### ImÃ¡genes Docker Generadas

- **Backend**: `ghcr.io/ladyfantasy/tpi_devops-backend:main`
- **Frontend**: `ghcr.io/ladyfantasy/tpi_devops-frontend:main`

#### Acceso a las ImÃ¡genes

- **GitHub Packages**: https://github.com/LadyFantasy/TPI_DEVOPS?tab=packages
- **Pull local**: `docker pull ghcr.io/ladyfantasy/tpi_devops-backend:main`
- **Pull local**: `docker pull ghcr.io/ladyfantasy/tpi_devops-frontend:main`

---

## ğŸ“¦ InstalaciÃ³n y ConfiguraciÃ³n

### ğŸ”§ Desarrollo Local

#### 1. **Prerrequisitos**

```bash
# Instalar Docker y Docker Compose
# Node.js 20+
# Python 3.11+
```

#### 2. **Clonar y Configurar**

```bash
git clone https://github.com/LadyFantasy/TPI_DEVOPS.git
cd TPI_DEVOPS
cp env.example .env
```

#### 3. **Variables de Entorno (Desarrollo)**

```env
# Base de Datos Local
DB_HOST=mysql
DB_PORT=3306
DB_NAME=ppiv_db
DB_USER=root
DB_PASSWORD=password

# Flask
SECRET_KEY=dev-secret-key
JWT_SECRET_KEY=dev-jwt-secret
IS_PRODUCTION=false
```

#### 4. **Iniciar Desarrollo**

```bash
# Iniciar todo el stack de desarrollo
docker-compose -f docker-compose.dev.yml up -d

# Verificar que todo estÃ© funcionando
docker-compose -f docker-compose.dev.yml ps
```

#### 5. **Acceso a la AplicaciÃ³n**

- **Frontend**: http://localhost:3000
- **Backend API**: http://localhost:5000
- **Base de datos**: localhost:3306

### ğŸŒ ProducciÃ³n (Deploy AutomÃ¡tico)

El proyecto se despliega automÃ¡ticamente en:

- **Backend**: Render (Flask API)
- **Frontend**: Vercel (React App)
- **Base de datos**: Filess.io (MySQL)

**No requiere configuraciÃ³n manual** - el pipeline CI/CD maneja todo automÃ¡ticamente.

---

## ğŸ“Š Monitoreo con Prometheus + Grafana

### ğŸš€ Iniciar el Stack de Monitoreo

```bash
# Crear red de Docker (si no existe)
docker network create ppiv_network

# Iniciar stack de monitoreo
docker-compose -f docker-compose.monitoring.yml up -d
```

### ğŸŒ Acceso a las Herramientas

- **Grafana**: http://localhost:3001 (admin/admin)
- **Prometheus**: http://localhost:9090

### ğŸ“ˆ Â¿QuÃ© Muestran los Dashboards?

#### **Grafana Dashboard Principal**

1. **ğŸŒ MÃ©tricas de AplicaciÃ³n**

   - HTTP Request Rate: Tasa de requests por segundo
   - Response Time: Tiempo de respuesta promedio
   - Error Rate: Porcentaje de errores HTTP
   - Active Connections: Conexiones activas

2. **ğŸ“Š MÃ©tricas del Sistema**

   - CPU Usage: Uso de procesador en tiempo real
   - Memory Usage: Consumo de memoria RAM
   - Disk Usage: Espacio en disco utilizado
   - Network Traffic: TrÃ¡fico de red

### ğŸ› ï¸ CÃ³mo Usar Grafana

#### **1. Acceder al Dashboard**

1. Abrir http://localhost:3001
2. Login: `admin` / `admin`
3. Ir a "Dashboards" â†’ "PPIV Dashboard"

#### **2. Navegar por los Paneles**

- **Panel Superior**: MÃ©tricas generales del sistema
- **Panel Izquierdo**: MÃ©tricas de aplicaciÃ³n
- **Panel Derecho**: MÃ©tricas de rendimiento

#### **3. Personalizar Dashboards**

1. Hacer clic en "Edit" en cualquier panel
2. Modificar queries de Prometheus
3. Cambiar visualizaciones
4. Guardar cambios

### ğŸ”§ ConfiguraciÃ³n de Prometheus

#### **Targets Monitoreados**

```yaml
# prometheus.yml
scrape_configs:
  - job_name: "prometheus"
    static_configs:
      - targets: ["localhost:9090"]

  - job_name: "ppiv-backend"
    static_configs:
      - targets: ["ppiv_backend_dev:5000"]
    metrics_path: "/metrics"
    scrape_interval: 10s

  - job_name: "ppiv-frontend"
    static_configs:
      - targets: ["ppiv_frontend_dev:3000"]
    metrics_path: "/metrics"
    scrape_interval: 10s
```

### ğŸ“Š MÃ©tricas EspecÃ­ficas del Proyecto

#### **Backend Flask**

- Requests por minuto
- Tiempo de respuesta promedio
- Errores 4xx y 5xx
- Uso de memoria por endpoint

#### **Frontend React**

- Tiempo de carga de pÃ¡ginas
- Errores de JavaScript
- MÃ©tricas de rendimiento
- Estado de build

---

## ğŸš¨ Troubleshooting

### âŒ Problemas Comunes

#### **1. Tests Fallan**

```bash
# Verificar que la app estÃ© corriendo
curl http://localhost:5000/health

# Revisar logs
docker-compose logs backend

# Ejecutar tests individualmente
python -m pytest tests/test_login.py -v
```

#### **2. Deploy Falla**

```bash
# Verificar variables de entorno
echo $DB_HOST
echo $SECRET_KEY

# Revisar logs de GitHub Actions
# Ir a: GitHub > Actions > Ver logs

# Verificar conectividad
curl https://tu-backend.onrender.com/health
```

#### **3. Base de Datos**

```bash
# Verificar conexiÃ³n
docker-compose exec mysql mysql -u ppiv_user -p

# Reinicializar datos
docker-compose down -v
docker-compose up -d
```

#### **4. Docker Issues**

```bash
# Limpiar Docker
docker system prune -a

# Reconstruir todo
docker-compose build --no-cache
docker-compose up -d
```

#### **5. Monitoreo No Funciona**

```bash
# Verificar que la red existe
docker network ls | grep ppiv_network

# Crear red si no existe
docker network create ppiv_network

# Reiniciar stack de monitoreo
docker-compose -f docker-compose.monitoring.yml down
docker-compose -f docker-compose.monitoring.yml up -d

# Verificar logs
docker-compose -f docker-compose.monitoring.yml logs -f
```

### ğŸ” Debugging

#### **Logs Ãštiles**

```bash
# Backend logs
docker-compose logs backend

# Frontend logs
docker-compose logs frontend

# Database logs
docker-compose logs mysql

# GitHub Actions logs
# GitHub > Actions > Workflow > Job > View logs

# Monitoreo logs
docker-compose -f docker-compose.monitoring.yml logs -f
```

#### **VerificaciÃ³n de Estado**

```bash
# Verificar servicios
docker-compose ps

# Verificar puertos
netstat -tulpn | grep :5000
netstat -tulpn | grep :3000

# Verificar variables de entorno
docker-compose exec backend env
```

---

## ğŸ—ï¸ Infraestructura como CÃ³digo - AnÃ¡lisis

### Archivos de Terraform

En el repositorio se incluyen archivos de configuraciÃ³n de Terraform (`terraform/main.tf`, `terraform/variables.tf`, y mÃ³dulos), pero **no estÃ¡n en uso actualmente** en el pipeline ni en producciÃ³n. Estos archivos estÃ¡n preparados para mostrar cÃ³mo se podrÃ­a aprovisionar infraestructura en la nube (por ejemplo, redes, instancias, bases de datos) si se migrara a un entorno IaaS como AWS, Azure o GCP.

Actualmente, toda la infraestructura se gestiona como PaaS (Render, Vercel, Filess.io), por lo que no es necesario aplicar Terraform, pero los archivos quedan como referencia y ejemplo de buenas prÃ¡cticas de Infraestructura como CÃ³digo.

### Arquitectura Actual

- **Backend**: Render (PaaS) - ConfiguraciÃ³n automÃ¡tica
- **Frontend**: Vercel (PaaS) - ConfiguraciÃ³n automÃ¡tica
- **Base de datos**: Filess.io (DBaaS) - ConfiguraciÃ³n automÃ¡tica
- **CI/CD**: GitHub Actions - ConfiguraciÃ³n automÃ¡tica

### Â¿Por quÃ© no Terraform?

1. **PaaS vs IaaS**: Render/Vercel son PaaS (Platform as a Service)

   - No es necesario gestionar servidores
   - ConfiguraciÃ³n automÃ¡tica
   - Terraform es mÃ¡s Ãºtil para IaaS (AWS, Azure, GCP)

2. **Costo vs Beneficio**:

   - PaaS gratuito vs IaaS con costos
   - Para este proyecto, PaaS es mÃ¡s eficiente

3. **Complejidad innecesaria**:
   - El pipeline ya estÃ¡ automatizado
   - Agregar Terraform serÃ­a over-engineering

---

## ğŸ¤ ContribuciÃ³n

1. **Fork** el repositorio
2. **Crea** una rama para tu feature (`git checkout -b feature/nueva-funcionalidad`)
3. **Commit** tus cambios (`git commit -am 'Agregar nueva funcionalidad'`)
4. **Push** a la rama (`git push origin feature/nueva-funcionalidad`)
5. **Crea** un Pull Request

### ğŸ“‹ Checklist para Contribuciones

- [ ] Tests pasando
- [ ] Linting sin errores
- [ ] DocumentaciÃ³n actualizada
- [ ] Variables de entorno documentadas
- [ ] Pipeline CI/CD funcionando

---

## ğŸ† Conclusiones y Roles del Equipo

### ğŸ‘¥ Roles y Responsabilidades

Este proyecto fue desarrollado por un equipo de 4 personas, cada una con responsabilidades especÃ­ficas que permitieron crear una aplicaciÃ³n completa y robusta:

#### **Soledad MartÃ­nez** - Project Manager & Frontend

- **Rol**: Liderazgo del proyecto y desarrollo frontend
- **Responsabilidades**:
  - GestiÃ³n del proyecto y planificaciÃ³n de sprints
  - Desarrollo de la interfaz con React y Vite
  - CoordinaciÃ³n entre frontend, backend y DevOps
  - DocumentaciÃ³n y presentaciÃ³n del proyecto
  - ConfiguraciÃ³n de CI/CD y monitoreo

#### **Guillermo KÃ¶ster** - Backend & Base de Datos

- **Rol**: Desarrollo del backend y gestiÃ³n de datos
- **Responsabilidades**:
  - Desarrollo de la API REST con Flask
  - DiseÃ±o y optimizaciÃ³n de la base de datos MySQL
  - ImplementaciÃ³n de autenticaciÃ³n JWT
  - ConfiguraciÃ³n de servicios de email
  - DockerizaciÃ³n del backend

#### **Carolina CerÃ³n** - UI/UX & DiseÃ±o

- **Rol**: DiseÃ±o de interfaz y experiencia de usuario
- **Responsabilidades**:
  - DiseÃ±o de componentes y estilos CSS
  - OptimizaciÃ³n de la experiencia de usuario
  - Responsive design y accesibilidad
  - CreaciÃ³n de wireframes y prototipos
  - Aseguramiento de la usabilidad del sistema

#### **GermÃ¡n Pappalardo** - Testing & Calidad

- **Rol**: Aseguramiento de calidad y testing
- **Responsabilidades**:
  - ImplementaciÃ³n de tests unitarios con pytest
  - Tests de integraciÃ³n y E2E con Selenium
  - ConfiguraciÃ³n de coverage y mÃ©tricas de calidad
  - ValidaciÃ³n de funcionalidades crÃ­ticas
  - Aseguramiento de la estabilidad del sistema

### ğŸ¯ Logros del Equipo

#### **Trabajo Colaborativo**

- **ComunicaciÃ³n efectiva** entre todos los roles
- **IntegraciÃ³n exitosa** de frontend, backend y DevOps
- **Cumplimiento de deadlines** y objetivos del proyecto
- **AplicaciÃ³n de mejores prÃ¡cticas** de desarrollo

#### **Resultados TÃ©cnicos**

- **AplicaciÃ³n funcional** con todas las caracterÃ­sticas solicitadas
- **Pipeline CI/CD completo** y automatizado
- **Monitoreo implementado** con Prometheus y Grafana
- **DocumentaciÃ³n exhaustiva** y clara
- **Cobertura de tests** superior al 85%

#### **Aprendizajes Adquiridos**

- **DevOps en la prÃ¡ctica**: CI/CD, Docker, monitoreo
- **Trabajo en equipo** con roles definidos
- **GestiÃ³n de proyectos** con metodologÃ­as Ã¡giles
- **IntegraciÃ³n de tecnologÃ­as** modernas
- **Despliegue en la nube** con servicios PaaS

### ğŸš€ Impacto del Proyecto

Este trabajo prÃ¡ctico demostrÃ³ la capacidad del equipo para:

- **Desarrollar aplicaciones completas** desde cero hasta producciÃ³n
- **Implementar prÃ¡cticas DevOps** modernas y efectivas
- **Trabajar colaborativamente** con roles bien definidos
- **Entregar productos de calidad** con documentaciÃ³n completa

El proyecto no solo cumple con todos los requisitos tÃ©cnicos solicitados, sino que tambiÃ©n demuestra las habilidades de trabajo en equipo y la capacidad de aplicar conocimientos teÃ³ricos en un proyecto real y funcional.

---

## ğŸ“ Soporte

- **ğŸ› Issues**: [GitHub Issues](https://github.com/LadyFantasy/TPI_DEVOPS/issues)

---

## ğŸ† Logros del Proyecto

### âœ… Funcionalidades Implementadas

1. **AplicaciÃ³n funcional** con frontend y backend
2. **DockerizaciÃ³n completa** con multi-stage builds
3. **CI/CD automatizado** con GitHub Actions
4. **Tests automatizados** (unitarios e integraciÃ³n)
5. **Build y push automÃ¡tico** a GitHub Container Registry
6. **Deploy automÃ¡tico** en mÃºltiples plataformas
7. **Monitoreo bÃ¡sico** con Prometheus + Grafana

### ğŸ¯ Beneficios Obtenidos

- **AutomatizaciÃ³n completa** del proceso de desarrollo
- **Despliegue confiable** y reproducible
- **Monitoreo bÃ¡sico** de la aplicaciÃ³n
- **Escalabilidad** con contenedores
- **Registry de imÃ¡genes** centralizado en GitHub

### ğŸ› ï¸ TecnologÃ­as Aprendidas

- **Docker** y **Docker Compose**
- **GitHub Actions** para CI/CD
- **GitHub Container Registry** para imÃ¡genes Docker
- **Prometheus** y **Grafana** para monitoreo bÃ¡sico
- **Render** y **Vercel** para deploy
- **Selenium** para testing de UI

## ğŸ› ï¸ Comandos Ãštiles

### ğŸ”§ Desarrollo Local

```bash
# Iniciar todo el stack de desarrollo
docker-compose -f docker-compose.dev.yml up -d

# Ver logs en tiempo real
docker-compose -f docker-compose.dev.yml logs -f

# Parar servicios
docker-compose -f docker-compose.dev.yml down

# Reconstruir imÃ¡genes
docker-compose -f docker-compose.dev.yml build --no-cache

# Acceder a la base de datos
docker-compose -f docker-compose.dev.yml exec mysql mysql -u root -p ppiv_db
```

### ğŸ§ª Tests

```bash
# Tests del backend
cd ProyectoPPVI
python -m pytest tests/ -v --cov=app

# Tests del frontend
cd PI-PPIV-Front
npm ci
npm run build

# Tests E2E
cd PI-PPIV-Front
python -m pytest tests/ -v
```

### ğŸ³ Docker

```bash
# Construir imÃ¡genes localmente
docker build -t ppiv-backend ./ProyectoPPVI
docker build -t ppiv-frontend ./PI-PPIV-Front

# Ejecutar contenedores individuales
docker run -p 5000:5000 ppiv-backend
docker run -p 3000:3000 ppiv-frontend
```

## ğŸ—‚ï¸ Estrategia de ramas (Git Flow)

- `main`: Rama principal, siempre estable y lista para producciÃ³n.
- `develop`: Rama de integraciÃ³n para nuevas funcionalidades.
- `feature/*`: Ramas para el desarrollo de nuevas features o fixes.

> En este proyecto, la estructura de ramas se implementÃ³ para cumplir con las mejores prÃ¡cticas de DevOps, aunque el desarrollo principal se realizÃ³ en `main` por ser un trabajo individual y cerrado.
